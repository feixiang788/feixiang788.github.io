[{"title":"卷积神经网络","date":"2022-02-20T14:15:38.000Z","url":"/2022/02/20/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","categories":[[" ",""]],"content":"读完《Deep Learning with Python》关于卷积神经网络部分，在惊讶于它的能力的时候，我觉得很有必要把这个概念总结一下，下面主要从4个方面来谈谈。 卷积神经网路是什么 卷积神经网络的由来 卷积神经网络的使用 卷积神经网络的启示 1.卷积神经网络是什么 卷积神经网络（Convolutional Neural Networks, CNN）是一类包含卷积计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习（deep learning）的代表算法之一。 这是来自《Deep Learning》书中的解释，这个解释更像是名词的扩展释义，在我看来，广有这个释义还不够，要想往再深一点理解卷积神经网络，就要知道卷积神经网络与其他神经网络不同的地方是什么？ 在我看来，卷积神经网络独特的地方在于其具有非常重要的2个性质： （1）卷积神经网络学到的模式具有平移不变性； （2）卷积神经网络可以学到模式的空间层次结构。 为什么有这样的性质，这还得从卷积神经网络的定义和运算过程讲起。 （略） 2.卷积神经网络的由来从百度百科上了解到卷积神经网络的起源可以追溯到我们改革开放初期，一位叫福岛邦彦的日本学者首先仿造生物识别的过程，创造了neocognitron，这个研究虽不是完整意义上的卷积神经网络，但却对今后卷积神经网络的诞生提供了一种参考和借鉴。 对卷积神经网络的研究可追溯至日本学者福岛邦彦（Kunihiko Fukushima）提出的neocognitron模型。在其1979年和1980年发表的论文中，福岛仿造生物的视觉皮层（visual cortex）设计了以“neocognitron”命名的神经网络。neocognitron是一个具有深度结构的神经网络，并且是最早被提出的深度学习算法之一，其隐含层由S层（Simple-layer）和C层（Complex-layer）交替构成。其中S层单元在感受野（receptive field）内对图像特征进行提取，C层单元接收和响应不同感受野返回的相同特征。neocognitron的S层-C层组合能够进行特征提取和筛选，部分实现了卷积神经网络中卷积层（convolution layer）和池化层（pooling layer）的功能，被认为是启发了卷积神经网络的开创性研究。 同样是从百度百科中知道，第一个卷积神经网络TDNN是Alexander Waibei提出的： 第一个卷积神经网络是1987年由Alexander Waibel等提出的时间延迟网络（Time Delay Neural Network, TDNN）。TDNN是一个应用于[语音识别]问题的卷积神经网络，使用FFT预处理的语音信号作为输入，其隐含层由2个一维卷积核组成，以提取频率域上的平移不变特征。由于在TDNN出现之前，人工智能领域在反向传播算法（Back-Propagation, BP）的研究中取得了突破性进展，因此TDNN得以使用BP框架内进行学习。在原作者的比较试验中，TDNN的表现超过了同等条件下的隐马尔可夫模型（Hidden Markov Model, HMM），而后者是二十世纪80年代语音识别的主流算法。 卷积神经网络的使用略 卷积神经网络的启示略"},{"title":"走向人工智能时代的我们","date":"2022-02-13T14:48:01.000Z","url":"/2022/02/13/%E8%B5%B0%E5%90%91%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3%E7%9A%84%E6%88%91%E4%BB%AC/","categories":[[" ",""]],"content":"从2010年就读大学以后，我们计算机专业和网络工程专业的同学就开始琢磨，如何才能实现我们这一代年轻人的价值？那个时候大家比较热衷的事情是希望能够开发一个牛逼的操作系统，打败windows的垄断，学校那个时候也在推广Ubuntu麒麟，当时没少帮同学装系统。在那个互联网还不够发达的年代，大家对于人工智能都是知之甚少，没有人能够预见人工智能将会对这个世界带来怎样的改变。 对我而言，在大学时代，关于人工智能最深的记忆主要有2个： 第一，2013年秋季，计算机学院祝老师开设了1门人工智能专业课，使用的教科书是非常经典的《Artificial Intelligence:A Modern Approach》(Stuart Russell and Peter Norvig)。当时由于时间有限，我们没有学完所有的章节，但在学习的过程中我受到了启发——计算机不仅仅是一个工具，它可以模拟我们某些思维过程，未来它可能会改变我们的社会。 第二，我在准备参加数模竞赛的时候，在某本书里面看到有用神经网络算法来做分类的，当时就觉得这个神经网络概念挺“高大上”的，没想到在这个概念的基础上衍生出了深度学习算法，人工智能在经历了寒冬季后迎来了爆发。AlphaGo、波士顿机器人、Tesla无人驾驶，过去许多只有人能完成的工作，机器同样可以完成！ 站在2022年新的历史起点，我们发现人工智能已经进入我们每个人的生活。在我看来，我们正在进入新的一个时代——“后人工智能时代”。我相信，在人工智能技术的演进推动下，我们的社会生活将会发生深刻改变。 在我看来，深处这个伟大的时代，我们不能按部就班等着时代来改变我们。尤其是对于有理想、有抱负、有想法的年轻人来说，我们应该主动去了解人工智能的研究现状，各个领域的能力边界和知识界限，然后想办法作出一点自己的贡献！对于一个从中国科学院大学人工智能学院毕业的研究生，虽然我目前没有从事相关的工作，但我依然希望能够继续回答自己硕士毕业论文的课题，如何让计算机建立认知体系。为了这个继续探索的伟大愿望，从本周开始，我将边学边记，再次阅读《Deep Learning with Python》（Francois Chollet），并将这个过程中的思考记录下来，我将以同学的口吻来告诉你我认为重要的概念和知识细节。期待在我的blog中记录下自己独特的思考！ 写于2022年2月14日凌晨，北京公主坟"},{"title":"“写在个人博客创建之初”","date":"2022-02-03T15:16:30.000Z","url":"/2022/02/03/%E5%86%99%E5%9C%A8%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E5%88%9B%E5%BB%BA%E4%B9%8B%E5%88%9D/","categories":[[" ",""]],"content":"为什么要创建这个博客从大学毕业以后，我一直在思考，如何才能在繁杂的事务性工作中，找到生命的乐趣或者人生的兴趣。遗憾的是，我尝试了各种各样的途径，但最后无一不是半途而废或者收效甚微。 比如，作为一名理工科出生的我，曾经对于coursera上的各种名校网络课非常着谜，投入了大量的时间进行广泛的学习，翻开我的coursera个人成就页面，可以看到深度学习（吴恩达系列）、Python（密歇根大学系列）、微观经济学原理（伊利诺伊大学香槟分校）、学会如何学习（Deep Teaching Solutions）等课程证书，但实际上这些证书并没有为我带来真正的认知和能力的提升！回过头看，我当初的之所以选择这些课程，主要还是想弥补自己的认知空白和技能盲点，但一味追求速度、不注重质量的突击式学习模式，注定是要失败的！学习不能囫囵吞枣，认知不会简单通过听别人讲就会快速提升，因为间接经验的简单传递不会在记忆深处留下痕迹，而是要通过思辨或者实验等方法，在曲折探索的过程中才会真正凝结。 所以，这也就是我要创建这个博客的第一个原因——“记录”，希望通过构建一个能够记录个人思辨过程的网络平台，让自己在即将踏入三十岁（博主1992年2月出生）的之前，逐步去养成深度思考的习惯，所以我会按照每周一篇文章（不少于500字）的速度去总结某个话题，希望大家能够多评论、多批评、多指正。我始终坚信，只有把自己归零，沉下心来思考，才能更好地出发！ 其实，作为一个从小学开始学习网页编程的伪geek，我一直就希望能够在www世界留下自己的足迹。因为一路走来，自己在各个涉足的领域积累了不少经验和教训，把这些东西分享出来，也许能够帮助你少走弯路，或者能够帮你解答疑惑，又或许能够帮你走出阴霾。总之，我希望能够在这片虚拟空间，为这个社会创造一点不一样的价值，好让自己六十岁的时候能够有一些值得回忆的东西。这就是我要创建这个博客的第二个原因——“分享”。 俗话说：万事开头难。幸运的是，我已经完成了博客的搭建。但是未来浇灌这片心灵的澄澈之地，还需要大量时间和精力的投入。莫问前程，但求无悔！立下几个重要的flag： 个人独立博客，绝不转载他人的博客文章。 绝对独立原创博文，如果需要图片，绝对不会盗图。 任何代码都要确保可读性，并经过验证、可复现。 让我们一起向未来！ 写在北京2022年冬奥会开幕之际，于北京海淀公主坟"},{"title":"search","date":"2022-02-03T16:13:02.000Z","url":"/search/index.html","categories":[[" ",""]]}]